# -*- coding: utf-8 -*-
"""news.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w7nKwE6P54FPOWaxg0vmBEZxpEbg4scB
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

def get_google_news(company_name, max_articles=10):
    # Google News RSS feed
    search_query = company_name.replace(" ", "+")
    url = f"https://news.google.com/rss/search?q={search_query}"

    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'xml')
    items = soup.find_all('item')

    news_data = []
    for item in items[:max_articles]:
        title = item.title.text
        link = item.link.text
        pub_date = item.pubDate.text
        description = item.description.text

        news_data.append({
            'Title': title,
            'Link': link,
            'Published Date': pub_date,
            'Summary': description
        })

    return pd.DataFrame(news_data)

# Example usage
company = "Tesla"
df_news = get_google_news(company)

import requests
from bs4 import BeautifulSoup
import pandas as pd
from textblob import TextBlob

# Step 1: Get Google News RSS articles
def get_google_news(company_name, max_articles=10):
    search_query = company_name.replace(" ", "+")
    url = f"https://news.google.com/rss/search?q={search_query}"

    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'xml')
    items = soup.find_all('item')

    news_data = []
    for item in items[:max_articles]:
        title = item.title.text
        link = item.link.text
        pub_date = item.pubDate.text
        description = item.description.text

        news_data.append({
            'Title': title,
            'Link': link,
            'Published Date': pub_date,
            'Summary': description
        })

    return pd.DataFrame(news_data)

# Step 2: Analyze sentiment
def get_sentiment(text):
    analysis = TextBlob(text)
    polarity = analysis.sentiment.polarity
    if polarity > 0:
        return 'Positive'
    elif polarity < 0:
        return 'Negative'
    else:
        return 'Neutral'

# Example usage
company = "Tesla"
df_news = get_google_news(company)

# Apply sentiment analysis to the Summary column
df_news['Sentiment'] = df_news['Summary'].apply(get_sentiment)

# Show result
df_news[['Title', 'Summary', 'Sentiment']]

# Step 3: Run and plot
company = "Tesla"
df_news = get_google_news(company)
df_news['Sentiment'] = df_news['Summary'].apply(get_sentiment)

# Plotting
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(6,4))
sns.countplot(data=df_news, x='Sentiment', palette='Set2')
plt.title(f"Sentiment Distribution for {company} News")
plt.xlabel("Sentiment")
plt.ylabel("Number of Articles")
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# Step 1: Sentiment Distribution Summary
sentiment_counts = df_news['Sentiment'].value_counts()

print("🔍 Sentiment Distribution:")
print(sentiment_counts)

# Step 2: Identify contrasting articles
comparisons = []
for i in range(len(df_news)):
    for j in range(i + 1, len(df_news)):
        if df_news['Sentiment'][i] != df_news['Sentiment'][j]:
            comparisons.append({
                'Article A': df_news['Title'][i],
                'Sentiment A': df_news['Sentiment'][i],
                'Article B': df_news['Title'][j],
                'Sentiment B': df_news['Sentiment'][j],
                'Observation': f"Contrast in tone: '{df_news['Title'][i][:40]}...' vs '{df_news['Title'][j][:40]}...'"
            })

# Convert to DataFrame
df_comparisons = pd.DataFrame(comparisons)

# Show top comparisons
print("\n⚖️ Sample Contrasts in Sentiment:")
df_comparisons.head(5)

!pip install gTTS

# Extract the 'Title' column and convert it to a list
titles_list = df_news['Title'].tolist()
titles_list

!pip install transformers
from transformers import pipeline
summarizer = pipeline("summarization", model="t5-small")
!pip install googletrans==4.0.0-rc1

# Concatenate all titles into one text (works better than summarizing short titles separately)
full_text = " ".join(df_news['Title'].tolist())

# Hugging Face models usually work best on up to 1024 tokens
from transformers import pipeline

summarizer = pipeline("summarization", model="t5-small")
summary = summarizer(full_text, max_length=60, min_length=20, do_sample=False)[0]['summary_text']

print("📝 Summary of Titles:")
print(summary)
!pip install googletrans==4.0.0-rc1
from googletrans import Translator

translator = Translator()
summary = summarizer(full_text, max_length=60, min_length=20, do_sample=False)[0]['summary_text']
translated = translator.translate(summary, src='en', dest='hi')
hindi_text = translated.text
print("🌐 Hindi Translation:\n", hindi_text)

from gtts import gTTS
from IPython.display import Audio

tts = gTTS(text=hindi_text, lang='hi')
tts.save("hindi_summary.mp3")

Audio("hindi_summary.mp3")

